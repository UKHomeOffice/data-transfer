pipeline:

  wait:
    image: martin/wait:latest
    commands:
      - /wait -c s3server:8000,sftp_server:2222

  make_bucket:
    image: brentley/awscli
    environment:
      - AWS_ACCESS_KEY_ID=accessKey1
      - AWS_SECRET_ACCESS_KEY=verySecretKey1
    commands:
      - aws --endpoint-url=http://s3server:8000 s3 mb s3://aws-ingest

  test:
    image: python:latest
    commands:
      - python3 -m venv .virtualenvs/data-transfer
      - . .virtualenvs/data-transfer/bin/activate
      - pip3 install -e . -r requirements.txt
      - export PYTHONPATH=.
      - pytest tests

  build:
    image: docker:17.09.1
    environment:
      - DOCKER_HOST=tcp://172.17.0.1:2375
    commands:
      - docker build -t data-transfer .
    when:
      branch: master
      event: push

  image_to_quay:
    image: docker:17.09.1
    secrets:
      - docker_username
      - docker_password
    environment:
      - DOCKER_HOST=tcp://172.17.0.1:2375
    commands:
      - docker login -u=$${DOCKER_USERNAME} -p=$${DOCKER_PASSWORD} quay.io
      - docker tag data-transfer quay.io/ukhomeofficedigital/data-transfer:$${DRONE_COMMIT_SHA}
      - docker push quay.io/ukhomeofficedigital/data-transfer:$${DRONE_COMMIT_SHA}
    when:
      branch: master
      event: push

services:
  sftp_server:
    image: atmoz/sftp:alpine
    commands:
      - echo "Port 2222" >> /etc/ssh/sshd_config
      - /entrypoint foo:pass:::upload

  s3server:
    environment:
      - ENDPOINT=s3server
      - BUCKET=aws-ingest
    image: scality/s3server:latest

  rabbitmq:
    image: rabbitmq:3
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=user
      - RABBITMQ_DEFAULT_PASS=password
